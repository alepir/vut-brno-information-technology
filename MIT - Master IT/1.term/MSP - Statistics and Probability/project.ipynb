{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSP Projekt\n",
    "Autor: Pavel Šesták"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom_test\n",
    "from scipy.stats import chi2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import scipy.stats as st\n",
    "import scipy.spatial as sp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LEN = 8\n",
    "#                      Praha, Brno, Znojmo, Tišnov, Paseky, Horní Lomná, Dolní Věstonice, okolí studenta\n",
    "numberOfRespondents = [1327,  915,  681,    587,    284,    176,         215,             32           ]\n",
    "winterTime          = [510,   324,  302,    257,    147,    66,          87,               5           ]\n",
    "summerTime          = [352,   284,  185,    178,    87,     58,          65,              12           ]\n",
    "changingTime        = [257,   178,  124,    78,     44,     33,          31,               7           ] \n",
    "OpinionLess         = [208,   129,  70,     74,     6,      19,          32,               8           ]\n",
    "\n",
    "DF = 4 - 1 #number of groups - 1\n",
    "ALPHA = .05\n",
    "\n",
    "BIG_CITIES = 0\n",
    "SMALL_CITIES = 1\n",
    "VILLAGES = 2\n",
    "STUDENT = 3\n",
    "\n",
    "NUMBER_OF_RESPONDENTS = \"numberOfRespondents\"\n",
    "WINTER = \"winter\"\n",
    "SUMMER = \"summer\"\n",
    "CHANGE = \"change\"\n",
    "OPINION_LESS = \"opinionLess\"\n",
    "CATEGORIES = [WINTER, SUMMER, CHANGE, OPINION_LESS]\n",
    "CATEGORIES_WITH_RESPONDETS = [WINTER, SUMMER, CHANGE, OPINION_LESS, NUMBER_OF_RESPONDENTS]\n",
    "\n",
    "indexes = [None] * 4\n",
    "indexes[BIG_CITIES] = [0, 1]\n",
    "indexes[SMALL_CITIES] = [2, 3]\n",
    "indexes[VILLAGES] = [4,5,6]\n",
    "indexes[STUDENT] = [7]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initData(dataSet, cats):\n",
    "    \"\"\"\n",
    "    This function initialize data\n",
    "\n",
    "    :param dataSet: array with 4 elements\n",
    "    :param cats: array of categories to initialize, different for dataset and expected\n",
    "    :return: initialized dataset for this task\n",
    "    \"\"\" \n",
    "    for i in range(4):\n",
    "        dataSet[i] = {}\n",
    "        for cat in cats:\n",
    "            dataSet[i][cat] = []\n",
    "\n",
    "def fillData(dataSet, indexes):\n",
    "    \"\"\"\n",
    "    This function fill dataset and aggregate to four categories\n",
    "\n",
    "    :pre initData\n",
    "    :param dataSet: initialized dataset\n",
    "    :param indexes: array of indexes for each categories to aggregate data\n",
    "    :return: aggregated data in dataset\n",
    "    \"\"\"\n",
    "    for i in range(4):\n",
    "        for j in indexes[i]:\n",
    "            dataSet[i][NUMBER_OF_RESPONDENTS].append(numberOfRespondents[j])\n",
    "            dataSet[i][WINTER].append(winterTime[j])\n",
    "            dataSet[i][SUMMER].append(summerTime[j])\n",
    "            dataSet[i][CHANGE].append(changingTime[j])\n",
    "            dataSet[i][OPINION_LESS].append(OpinionLess[j])\n",
    "            if(numberOfRespondents[j] != (winterTime[j] + summerTime[j] + changingTime[j] + OpinionLess[j])):\n",
    "                print(\"ERROR>>>\"+\" corrupted data for index: \", i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = [None] * 4\n",
    "initData(dataSet, CATEGORIES_WITH_RESPONDETS)\n",
    "fillData(dataSet, indexes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate X2 for all categories in one test \n",
    "\n",
    "https://sites.ualberta.ca/~lkgray/uploads/7/3/6/2/7362679/slides_-_binomialproportionaltests.pdf\n",
    "\n",
    "#### Calculate totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = {}\n",
    "totals[NUMBER_OF_RESPONDENTS] = sum(numberOfRespondents)\n",
    "totals[WINTER] = sum(winterTime)\n",
    "totals[SUMMER] = sum(summerTime)\n",
    "totals[CHANGE] = sum(changingTime)\n",
    "totals[OPINION_LESS] = sum(OpinionLess)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = {}\n",
    "for cat in CATEGORIES:\n",
    "    averages[cat] = totals[cat]/totals[NUMBER_OF_RESPONDENTS]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillExpected(expectedDataset, dataSet):\n",
    "    \"\"\"\n",
    "    This function calculate expected matrix\n",
    "\n",
    "    :pre initData for both params\n",
    "    :param expectedDataset: initialized expected matrix\n",
    "    :param dataSet: filled dataset\n",
    "    :return: filled expected matrix\n",
    "    \"\"\"\n",
    "    for i in range(4):\n",
    "        for cat in CATEGORIES:\n",
    "            expectedDataset[i][cat] = sum(dataSet[i][NUMBER_OF_RESPONDENTS]) * averages[cat]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate x2 and check hypothesis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x2:  41.95905515385538\n",
      "critical:  7.814727903251179\n",
      "H0 rejected\n"
     ]
    }
   ],
   "source": [
    "\n",
    "expected = [None] * 4\n",
    "initData(expected, CATEGORIES)\n",
    "fillExpected(expected, dataSet)\n",
    "\n",
    "#calc x2\n",
    "x2 = 0\n",
    "\n",
    "for i in range(4):\n",
    "    for k in CATEGORIES:\n",
    "        x2 += ((sum(dataSet[i][k]) - expected[i][k]) ** 2) / expected[i][k]\n",
    "\n",
    "print(\"x2: \", x2)\n",
    "\n",
    "critical = chi2.ppf(1-ALPHA, df=DF)\n",
    "\n",
    "print(\"critical: \", critical)\n",
    "\n",
    "if x2 > critical:\n",
    "    print(\"H0 rejected\")\n",
    "else:\n",
    "    print(\"H0 NOT rejected\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reject the hypothesis of equality of all categories, now we can test the hypothesis for individual pairs.\n",
    "We define function to calculate x2, then we will call it for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateX2(cat):\n",
    "    \"\"\"\n",
    "    This function calculate x2\n",
    "\n",
    "    :pre calculate dataset and expected\n",
    "    :param cat: defines which category we will test\n",
    "    :return: result of x2\n",
    "    \"\"\"\n",
    "    data_ = []\n",
    "    expected_ = []\n",
    "    for i in range(4):\n",
    "        data_.append(np.sum(dataSet[i][cat]))\n",
    "        expected_.append(expected[i][cat])\n",
    "\n",
    "    print(\"dataset: \",data_)\n",
    "    print(\"expected: \", expected_)\n",
    "    x2Result = st.chisquare(data_, expected_, ddof=DF)\n",
    "    print(\"x2 test result:\", x2Result)\n",
    "\n",
    "    if x2Result.pvalue < ALPHA:\n",
    "        print(\"H0 rejected\")\n",
    "    else:\n",
    "        print(\"H0 NOT rejected\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  [834, 559, 300, 15]\n",
      "expected:  [907.2106135986733, 513.0878938640133, 273.13432835820896, 14.567164179104477]\n",
      "x2 test result: Power_divergenceResult(statistic=12.671683831272512, pvalue=nan)\n",
      "H0 NOT rejected\n"
     ]
    }
   ],
   "source": [
    "calculateX2(WINTER)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  [636, 363, 210, 9]\n",
      "expected:  [646.9452736318408, 365.89054726368164, 194.77611940298507, 10.388059701492537]\n",
      "x2 test result: Power_divergenceResult(statistic=1.583397846730724, pvalue=nan)\n",
      "H0 NOT rejected\n"
     ]
    }
   ],
   "source": [
    "calculateX2(SUMMER)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  [435, 202, 108, 7]\n",
      "expected:  [399.42762378583274, 225.90286661928454, 120.25586353944563, 6.4136460554371]\n",
      "x2 test result: Power_divergenceResult(statistic=6.9998505470210715, pvalue=nan)\n",
      "H0 NOT rejected\n"
     ]
    }
   ],
   "source": [
    "calculateX2(CHANGE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winterVector: [834. 559. 300.]\n",
      "winterPst: 0.4045400238948626\n",
      "expectedWinter: [906.97873357 512.9567503  273.06451613]\n",
      "Power_divergenceResult(statistic=12.661948651569508, pvalue=nan)\n",
      "H0 NOT rejected\n"
     ]
    }
   ],
   "source": [
    "winterVector = np.empty(shape=3)\n",
    "for i in range(3):\n",
    "    winterVector[i] = (np.sum(dataSet[i][WINTER]))\n",
    "\n",
    "print(\"winterVector:\", winterVector)\n",
    "\n",
    "winterSum = 0\n",
    "respondentSum = 0\n",
    "#winterPst = np.empty(shape=3, dtype=float)\n",
    "for i in range(3):\n",
    "    winterSum += np.sum(dataSet[i][WINTER])\n",
    "    respondentSum += np.sum(dataSet[i][NUMBER_OF_RESPONDENTS])\n",
    "    \n",
    "winterPst = winterSum / respondentSum\n",
    "print(\"winterPst:\", winterPst)\n",
    "\n",
    "expectedWinter = np.empty(shape=3, dtype=float)\n",
    "\n",
    "for i in range(3):\n",
    "    expectedWinter[i] = np.sum(dataSet[i][NUMBER_OF_RESPONDENTS]) * winterPst\n",
    "\n",
    "print(\"expectedWinter:\", expectedWinter)\n",
    "\n",
    "x2Result = st.chisquare(winterVector, expectedWinter,ddof=DF)\n",
    "print(x2Result)\n",
    "\n",
    "if x2Result.pvalue < ALPHA:\n",
    "    print(\"H0 rejected\")\n",
    "else:\n",
    "    print(\"H0 NOT rejected\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opinionLessVector: [337. 144.  57.]\n",
      "winterPst: 0.12855436081242533\n",
      "expectedWinter: [288.21887694 163.00692951  86.77419355]\n",
      "Power_divergenceResult(statistic=20.688664757394136, pvalue=nan)\n",
      "H0 NOT rejected\n"
     ]
    }
   ],
   "source": [
    "opinionLessVector = np.empty(shape=3)\n",
    "for i in range(3):\n",
    "    opinionLessVector[i] = (np.sum(dataSet[i][OPINION_LESS]))\n",
    "\n",
    "print(\"opinionLessVector:\", opinionLessVector)\n",
    "\n",
    "opinionLessSum = 0\n",
    "respondentSum = 0\n",
    "#winterPst = np.empty(shape=3, dtype=float)\n",
    "for i in range(3):\n",
    "    opinionLessSum += np.sum(dataSet[i][OPINION_LESS])\n",
    "    respondentSum += np.sum(dataSet[i][NUMBER_OF_RESPONDENTS])\n",
    "    \n",
    "opinionLessPst = opinionLessSum / respondentSum\n",
    "print(\"winterPst:\", opinionLessPst)\n",
    "\n",
    "expectedWinter = np.empty(shape=3, dtype=float)\n",
    "\n",
    "for i in range(3):\n",
    "    expectedWinter[i] = np.sum(dataSet[i][NUMBER_OF_RESPONDENTS]) * opinionLessPst\n",
    "\n",
    "print(\"expectedWinter:\", expectedWinter)\n",
    "\n",
    "x2Result = st.chisquare(opinionLessVector, expectedWinter, ddof=DF)\n",
    "print(x2Result)\n",
    "\n",
    "if x2Result.pvalue < ALPHA:\n",
    "    print(\"H0 rejected\")\n",
    "else:\n",
    "    print(\"H0 NOT rejected\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 f)\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.jensenshannon.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psts\n",
      "[[0.3719893  0.28367529 0.19402319 0.15031222]\n",
      " [0.44085174 0.2862776  0.15930599 0.11356467]\n",
      " [0.44444444 0.31111111 0.16       0.08444444]\n",
      " [0.41666667 0.25       0.19444444 0.13888889]]\n",
      "Deltas\n",
      "[array([ 0.04467737, -0.03367529,  0.00042125, -0.01142333]), array([-0.02418507, -0.0362776 ,  0.03513845,  0.02532422]), array([-0.02777778, -0.06111111,  0.03444444,  0.05444444])]\n",
      "Square errors\n",
      "BigCities\t\tSmallCities\t\tVillages\n",
      "[0.0901972445237387, 0.12092534174553098, 0.17777777777777776]\n",
      "Jensen–Shannon divergence\n",
      "BigCities\t\tSmallCities\t\tVillages\n",
      "[0.03574376779741301, 0.0479031856994284, 0.07798216224934762]\n"
     ]
    }
   ],
   "source": [
    "def getPstVec(entity):\n",
    "    pstVec = np.empty(shape=4, dtype=float)\n",
    "    index = 0\n",
    "    for cat in CATEGORIES:\n",
    "        pstVec[index] = np.sum(dataSet[entity][cat]) / np.sum(dataSet[entity][NUMBER_OF_RESPONDENTS])\n",
    "        index += 1\n",
    "    return pstVec\n",
    "\n",
    "psts = np.eye(4,4)\n",
    "for i in range(4):\n",
    "    psts[i] = getPstVec(i)\n",
    "\n",
    "print(\"psts\")\n",
    "print(psts)\n",
    "\n",
    "deltas = []\n",
    "for i in range(3):\n",
    "    deltas.append(psts[STUDENT] - psts[i])\n",
    "\n",
    "print(\"Deltas\")\n",
    "print(deltas)\n",
    "\n",
    "squareErrorVector = []\n",
    "for i in range(3):\n",
    "    squareErrorVector.append(np.sum(np.abs(deltas[i])))\n",
    "\n",
    "print(\"Square errors\")\n",
    "print(\"BigCities\\t\\tSmallCities\\t\\tVillages\")\n",
    "print(squareErrorVector)\n",
    "\n",
    "jensenshannonDistanceVector = []\n",
    "for i in range(3):\n",
    "    jensenshannonDistanceVector.append(sp.distance.jensenshannon(psts[STUDENT], psts[i]))\n",
    "\n",
    "print(\"Jensen–Shannon divergence\")\n",
    "print(\"BigCities\\t\\tSmallCities\\t\\tVillages\")\n",
    "print(jensenshannonDistanceVector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least squares error is in large cities. The Jensen-Shannon divergence is also smallest for large cities. This corresponds to where the data was collected. The data was collected in Brno and the questionnaire was filled out by my family and friends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules\n",
    "\n",
    "* Pandas - Pandas is used to store data in data frames\n",
    "* Statsmodels - This library is used for linear regression\n",
    "* Numpy - Math library for basic calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset\n",
    "Z index data is defined in MSP_Projekt_2022-23_Zadani_Ct-10.xls with index 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'x': [ 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 2.22, 2.22, 2.22, 2.22, 2.22, 2.22, 2.22, 4.44, 4.44, 4.44, 4.44, 4.44, 4.44, 4.44, 6.67, 6.67, 6.67, 6.67, 6.67, 6.67, 6.67, 8.89, 8.89, 8.89, 8.89, 8.89, 8.89, 8.89, 11.11, 11.11, 11.11, 11.11, 11.11, 11.11, 11.11, 13.33, 13.33, 13.33, 13.33, 13.33, 13.33, 13.33, 15.56, 15.56, 15.56, 15.56, 15.56, 15.56, 15.56, 17.78, 17.78, 17.78, 17.78, 17.78, 17.78, 17.78, 20.00, 20.00, 20.00, 20.00, 20.00, 20.00, 20.00],\n",
    "    'y': [ 0.00, 1.67, 3.33, 5.00, 6.67, 8.33, 10.00, 0.00, 1.67, 3.33, 5.00, 6.67, 8.33, 10.00, 0.00, 1.67, 3.33, 5.00, 6.67, 8.33, 10.00, 0.00, 1.67, 3.33, 5.00, 6.67, 8.33, 10.00, 0.00, 1.67, 3.33, 5.00, 6.67, 8.33, 10.00, 0.00, 1.67, 3.33, 5.00, 6.67, 8.33, 10.00, 0.00, 1.67, 3.33, 5.00, 6.67, 8.33, 10.00, 0.00, 1.67, 3.33, 5.00, 6.67, 8.33, 10.00, 0.00, 1.67, 3.33, 5.00, 6.67, 8.33, 10.00, 0.00, 1.67, 3.33, 5.00, 6.67, 8.33, 10.00 ],\n",
    "    'z': [-35.61, 78.11, -39.84, 64.09, 117.58, 55.45, 40.28, -20.67, 17.31, 79.04, -213.48, -144.45, -94.36, -193.02, -66.38, 161.15, -59.7, -66.83, 14.17, -207.41, -179.98, 264.75, 172.09, 51.32, 67.66, -20.13, -144.37, -174.38, 442.82, 340.21, 201.94, -34.12, -5.78, 31.38, -261.55, 457.5, 618.18, 335.88, 218.06, 76.66, 100.49, -101.64, 737.57, 568.3, 473.15, 370.03, 322.74, 179.21, -5.03, 1030.95, 851.61, 726.03, 573.27, 398.04, 364.79, 313.34, 1430.86, 1112.19, 1052.76, 701.14, 605.7, 458.74, 326.59, 1772, 1473.25, 1358.47, 1137.05, 920.43, 688.66, 498.32],     \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting\n",
    "In this part of code we will try to find model which best fit our data. We iterate over formulas and store the best model with the highest R2.\\\n",
    "Our base model is: $Z = \\beta_1 + \\beta_2 X + \\beta_3 Y + \\beta_4 X^2 \\beta_5 Y^2 + \\beta_6 XY$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "formulas = [\n",
    "        (df.x, df.y, df.x**2, df.y**2, df.x*df.y),\n",
    "        (df.x, df.y, df.x**2, df.y**2),\n",
    "        (df.x, df.y, df.x**2),\n",
    "        (df.x, df.y),\n",
    "        (df.x),\n",
    "        (),\n",
    "]\n",
    "index = 0\n",
    "bestFormula = None\n",
    "bestModel = None\n",
    "bestR2 = 0.0\n",
    "\n",
    "for formula in formulas:\n",
    "        if index < 4:\n",
    "                f = np.column_stack(formula)\n",
    "                f = sm.add_constant(f)\n",
    "        elif index == 4:\n",
    "                f = formula\n",
    "                f = sm.add_constant(f)\n",
    "        else:\n",
    "                f = sm.add_constant(df[['x','y']])\n",
    "        \n",
    "        model = sm.OLS(df.z, f).fit()\n",
    "\n",
    "        if bestR2 < model.rsquared:\n",
    "                bestFormula = formula\n",
    "                bestModel = model\n",
    "                bestR2 = model.rsquared\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze summary statistics of the best found model\n",
    "Our coefficient of determination is 0.975. This is very good result, maybe is our model overfitted. Method how to check is model is overfitted is to split dataset to two sets. One set for training and one for evaluation and check results.\n",
    "In second datatable we analyze p-values of t-test which verify H0 coefficient is equal to zero which implies its doesnt add any information to our model. t-test is comapred to aplha confidence level 0.05. We can remove from our model constant, x1, x2 and x4 without loss accurance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model summary\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      z   R-squared:                       0.975\n",
      "Model:                            OLS   Adj. R-squared:                  0.973\n",
      "Method:                 Least Squares   F-statistic:                     491.3\n",
      "Date:                Sun, 11 Dec 2022   Prob (F-statistic):           1.24e-49\n",
      "Time:                        17:05:42   Log-Likelihood:                -399.09\n",
      "No. Observations:                  70   AIC:                             810.2\n",
      "Df Residuals:                      64   BIC:                             823.7\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4333     36.246      0.067      0.947     -69.976      74.842\n",
      "x1             4.2885      5.655      0.758      0.451      -7.008      15.585\n",
      "x2            -2.6971     10.677     -0.253      0.801     -24.026      18.632\n",
      "x3             4.0409      0.252     16.023      0.000       3.537       4.545\n",
      "x4             0.3091      0.941      0.329      0.744      -1.570       2.189\n",
      "x5            -5.8401      0.425    -13.729      0.000      -6.690      -4.990\n",
      "==============================================================================\n",
      "Omnibus:                        0.111   Durbin-Watson:                   1.971\n",
      "Prob(Omnibus):                  0.946   Jarque-Bera (JB):                0.014\n",
      "Skew:                           0.031   Prob(JB):                        0.993\n",
      "Kurtosis:                       2.970   Cond. No.                         839.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model summary\")\n",
    "print(bestModel.summary())\n",
    "tt = bestModel.t_test(np.eye(len(bestModel.params)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce best model and remove unnecesary coefficiets\n",
    "In this section we will verify if our small model trully didnt loss accurance.\n",
    "Our coefficient of determination is 0.983 which is better result then the model with all coefficients and we can finish our analyzation with this model (Without constant).\n",
    "We need constant in our model, because without constant factor we cannot compute r-squared.\n",
    "t_test show p values are equal to zero, this coefficients are most signifficant for our model.\n",
    "\n",
    "Our final model is $Z = \\beta_1 + \\beta_3 X^2 + \\beta_5 XY$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small model summary\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      z   R-squared:                       0.974\n",
      "Model:                            OLS   Adj. R-squared:                  0.974\n",
      "Method:                 Least Squares   F-statistic:                     1271.\n",
      "Date:                Sun, 11 Dec 2022   Prob (F-statistic):           5.23e-54\n",
      "Time:                        17:05:42   Log-Likelihood:                -399.47\n",
      "No. Observations:                  70   AIC:                             804.9\n",
      "Df Residuals:                      67   BIC:                             811.7\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         13.8804     13.522      1.027      0.308     -13.109      40.870\n",
      "x1             4.2243      0.084     50.166      0.000       4.056       4.392\n",
      "x2            -5.7743      0.220    -26.274      0.000      -6.213      -5.336\n",
      "==============================================================================\n",
      "Omnibus:                        0.360   Durbin-Watson:                   1.943\n",
      "Prob(Omnibus):                  0.835   Jarque-Bera (JB):                0.067\n",
      "Skew:                           0.053   Prob(JB):                        0.967\n",
      "Kurtosis:                       3.108   Cond. No.                         307.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "smallModelF = np.column_stack((df.x**2, df.x*df.y))\n",
    "\n",
    "smallModelF = sm.add_constant(smallModelF)\n",
    "smallModel = sm.OLS(df.z, smallModelF).fit()\n",
    "\n",
    "print(\"Small model summary\")\n",
    "print(smallModel.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of regression parameters \n",
    "Estimations of regression parameters by the method least squares and their 95% confidence intervals which is calculated in model summary.\\\n",
    "$\\beta_1 \\in <-13.109; 40.870>$\\\n",
    "$\\beta_3 \\in <4.102; 4.413>$\\\n",
    "$\\beta_5 \\in <-6.131; -5.290>$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of dispersion\n",
    "Our final model is $Z = \\beta_1 + \\beta_3 X^2 + \\beta_5 XY$\\\n",
    "For estimation of dispersion we use modified equation from lecture MSP about linear regresion\\\n",
    "$s^2 = \\frac{1}{n-2}(\\sum_i^n z_i^2 - \\beta_3 \\sum_i^n x_i^2 z_i - \\beta_5 \\sum_i^n x_i y_i z_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation of dispersion:  5538.279525128775\n",
      "Dispersion from model:  5300.924688337542\n"
     ]
    }
   ],
   "source": [
    "s2 = smallModel.ssr/(len(df.z)-3)\n",
    "print(\"Estimation of dispersion: \", s2)\n",
    "\n",
    "xiyi = np.column_stack((np.power(df.x,2), df.x*df.y))\n",
    "xiyi = sm.add_constant(xiyi)\n",
    "z_predict = smallModel.predict(xiyi)\n",
    "\n",
    "print(\"Dispersion from model: \", np.var(df.z - z_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test hypothesis $\\beta_3 = \\beta_5 = 0$\n",
    "p-value is lower than alpha, we reject hypothese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<F test: F=1271.290092079406, p=5.228646164191333e-54, df_denom=67, df_num=2>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallModel.f_test(\"x1 = x2 = 0\").summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero equality f test is rejected\n",
    "### Test hypothesis $\\beta_3 = \\beta_5$\n",
    "t test and f test both reject hypotheses about equality of coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Test for Constraints                             \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "c0             9.9987      0.279     35.853      0.000       9.442      10.555\n",
      "==============================================================================\n",
      "<F test: F=1285.4690812507552, p=1.8998855078551346e-45, df_denom=67, df_num=1>\n"
     ]
    }
   ],
   "source": [
    "print(smallModel.t_test(\"x1 = x2\").summary())\n",
    "print(smallModel.f_test(\"x1 = x2\").summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficient equality f test and t test is rejected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c00dff4dd1fe3c4488bcb30e9e619fcf436e9ec51ea5d9f16534d0a167dbb912"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
